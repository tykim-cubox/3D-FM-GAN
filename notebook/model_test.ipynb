{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchinfo import summary\n",
    "sys.path.append('/workspace/gan/3D-FM-GAN')\n",
    "\n",
    "from models.encoders.helpers import get_blocks, Flatten, bottleneck_IR, bottleneck_IR_SE\n",
    "\n",
    "from models.networks import FMGAN, EncoderW, EncoderT, GradualStyleEncoder, FMGenerator\n",
    "from torch.nn import Linear, Conv2d, BatchNorm2d, PReLU, Sequential, Module\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class make_empty_object(object):\n",
    "    pass\n",
    "\n",
    "args = make_empty_object()\n",
    "args.wplus_num_layers = 50\n",
    "args.output_size = 256\n",
    "args.input_size = 256\n",
    "args.ckpt = '/workspace/gan/3D-FM-GAN/pretraiend/550000.pt'\n",
    "fmg = FMGenerator(args)\n",
    "\n",
    "# accelerator.device: cuda\n",
    "fmg = accelerator.prepare(fmg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stylegan': device(type='cuda', index=0),\n",
       " 'enc_t': device(type='cuda', index=0),\n",
       " 'enc_w': device(type='cuda', index=0),\n",
       " 'enc_wplus': device(type='cuda', index=0)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fmg.cuda()\n",
    "fmg.device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 512]) torch.Size([3, 14, 512])\n"
     ]
    }
   ],
   "source": [
    "result = fmg(torch.randn(3, 3, 256, 256).to('cuda'), torch.randn(3, 3, 256, 256).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 256, 256])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "styles = nn.ModuleList()\n",
    "coarse_ind = 3\n",
    "middle_ind = 7\n",
    "\n",
    "for i in range(n_styles):\n",
    "  if i < coarse_ind:\n",
    "      style = GradualStyleBlock(512, 512, 16)\n",
    "  elif i < middle_ind:\n",
    "      style = GradualStyleBlock(512, 512, 32)\n",
    "  else:\n",
    "      style = GradualStyleBlock(512, 512, 64)\n",
    "  styles.append(style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of models.encoders.helpers failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 317, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 280, in update_instances\n",
      "    ref.__class__ = new\n",
      "TypeError: __class__ assignment: 'Bottleneck' object layout differs from 'Bottleneck'\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_wplus = GradualStyleEncoder(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 14, 512])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_wplus(torch.randn(2, 3, 256, 256)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bottleneck_IR(\n",
      "  (shortcut_layer): MaxPool2d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (res_layer): Sequential(\n",
      "    (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): PReLU(num_parameters=64)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "1 bottleneck_IR(\n",
      "  (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (res_layer): Sequential(\n",
      "    (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): PReLU(num_parameters=64)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "2 bottleneck_IR(\n",
      "  (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (res_layer): Sequential(\n",
      "    (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): PReLU(num_parameters=64)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "3 bottleneck_IR(\n",
      "  (shortcut_layer): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (res_layer): Sequential(\n",
      "    (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): PReLU(num_parameters=128)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "4 bottleneck_IR(\n",
      "  (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (res_layer): Sequential(\n",
      "    (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): PReLU(num_parameters=128)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "5 bottleneck_IR(\n",
      "  (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (res_layer): Sequential(\n",
      "    (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): PReLU(num_parameters=128)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "6 bottleneck_IR(\n",
      "  (shortcut_layer): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (res_layer): Sequential(\n",
      "    (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): PReLU(num_parameters=256)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "7 bottleneck_IR(\n",
      "  (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (res_layer): Sequential(\n",
      "    (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): PReLU(num_parameters=256)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "8 bottleneck_IR(\n",
      "  (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (res_layer): Sequential(\n",
      "    (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): PReLU(num_parameters=256)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "9 bottleneck_IR(\n",
      "  (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (res_layer): Sequential(\n",
      "    (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): PReLU(num_parameters=256)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "10 bottleneck_IR(\n",
      "  (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (res_layer): Sequential(\n",
      "    (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): PReLU(num_parameters=256)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "11 bottleneck_IR(\n",
      "  (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (res_layer): Sequential(\n",
      "    (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): PReLU(num_parameters=256)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "12 bottleneck_IR(\n",
      "  (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (res_layer): Sequential(\n",
      "    (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): PReLU(num_parameters=256)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "13 bottleneck_IR(\n",
      "  (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (res_layer): Sequential(\n",
      "    (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): PReLU(num_parameters=256)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "14 bottleneck_IR(\n",
      "  (shortcut_layer): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (res_layer): Sequential(\n",
      "    (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): PReLU(num_parameters=512)\n",
      "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "15 bottleneck_IR(\n",
      "  (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (res_layer): Sequential(\n",
      "    (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): PReLU(num_parameters=512)\n",
      "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "16 bottleneck_IR(\n",
      "  (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (res_layer): Sequential(\n",
      "    (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): PReLU(num_parameters=512)\n",
      "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "modulelist = enc_wplus.body._modules.values()\n",
    "for i, l in enumerate(modulelist):\n",
    "    print(i, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradualStyleEncodaer(nn.Module):\n",
    "    def __init__(self, num_layers, mode='ir', output_size=256, input_nc=3):\n",
    "        super().__init__()\n",
    "        if mode == 'ir':\n",
    "            unit_module = bottleneck_IR\n",
    "        elif mode == 'ir_se':\n",
    "            unit_module = bottleneck_IR_SE\n",
    "\n",
    "        \n",
    "\n",
    "        self.input_layer = Sequential(Conv2d(input_nc, 64, (3, 3), 1, 1, bias=False),\n",
    "                                      BatchNorm2d(64),\n",
    "                                      PReLU(64))\n",
    "\n",
    "        n_styles = int(math.log(output_size, 2)) * 2 - 2\n",
    "        self.styles = nn.ModuleList()\n",
    "        self.style_count = n_styles\n",
    "        self.coarse_ind = 3\n",
    "        self.middle_ind = 7\n",
    "        for i in range(self.style_count):\n",
    "            if i < self.coarse_ind:\n",
    "                style = GradualStyleBlock(512, 512, 16)\n",
    "            elif i < self.middle_ind:\n",
    "                style = GradualStyleBlock(512, 512, 32)\n",
    "            else:\n",
    "                style = GradualStyleBlock(512, 512, 64)\n",
    "            self.styles.append(style)\n",
    "\n",
    "            \n",
    "        self.latlayer1 = nn.Conv2d(256, 512, kernel_size=1, stride=1, padding=0)\n",
    "        self.latlayer2 = nn.Conv2d(128, 512, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "\n",
    "        latents = []\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_w = EncoderW()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_w(torch.randn(2, 3, 256, 256)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_t = EncoderT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512, 4, 4])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_t(torch.randn(2, 3, 256, 256)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "n_styles = int(math.log(1024, 2)) * 2 - 2\n",
    "n_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "\n",
    "resnet = resnet18(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.nn.Conv2d(512, 512, kernel_size=3, padding=1, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512, 4, 4])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(enc_t(torch.randn(2, 3, 256, 256))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512, 1, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_w = Encoder('modulation')\n",
    "enc_w(torch.randn(2, 3, 256, 256)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [16, 1000]                --\n",
       "├─Conv2d: 1-1                            [16, 64, 64, 64]          9,408\n",
       "├─BatchNorm2d: 1-2                       [16, 64, 64, 64]          128\n",
       "├─ReLU: 1-3                              [16, 64, 64, 64]          --\n",
       "├─MaxPool2d: 1-4                         [16, 64, 32, 32]          --\n",
       "├─Sequential: 1-5                        [16, 64, 32, 32]          --\n",
       "│    └─BasicBlock: 2-1                   [16, 64, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-1                  [16, 64, 32, 32]          36,864\n",
       "│    │    └─BatchNorm2d: 3-2             [16, 64, 32, 32]          128\n",
       "│    │    └─ReLU: 3-3                    [16, 64, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-4                  [16, 64, 32, 32]          36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [16, 64, 32, 32]          128\n",
       "│    │    └─ReLU: 3-6                    [16, 64, 32, 32]          --\n",
       "│    └─BasicBlock: 2-2                   [16, 64, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-7                  [16, 64, 32, 32]          36,864\n",
       "│    │    └─BatchNorm2d: 3-8             [16, 64, 32, 32]          128\n",
       "│    │    └─ReLU: 3-9                    [16, 64, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-10                 [16, 64, 32, 32]          36,864\n",
       "│    │    └─BatchNorm2d: 3-11            [16, 64, 32, 32]          128\n",
       "│    │    └─ReLU: 3-12                   [16, 64, 32, 32]          --\n",
       "├─Sequential: 1-6                        [16, 128, 16, 16]         --\n",
       "│    └─BasicBlock: 2-3                   [16, 128, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-13                 [16, 128, 16, 16]         73,728\n",
       "│    │    └─BatchNorm2d: 3-14            [16, 128, 16, 16]         256\n",
       "│    │    └─ReLU: 3-15                   [16, 128, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-16                 [16, 128, 16, 16]         147,456\n",
       "│    │    └─BatchNorm2d: 3-17            [16, 128, 16, 16]         256\n",
       "│    │    └─Sequential: 3-18             [16, 128, 16, 16]         8,448\n",
       "│    │    └─ReLU: 3-19                   [16, 128, 16, 16]         --\n",
       "│    └─BasicBlock: 2-4                   [16, 128, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-20                 [16, 128, 16, 16]         147,456\n",
       "│    │    └─BatchNorm2d: 3-21            [16, 128, 16, 16]         256\n",
       "│    │    └─ReLU: 3-22                   [16, 128, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-23                 [16, 128, 16, 16]         147,456\n",
       "│    │    └─BatchNorm2d: 3-24            [16, 128, 16, 16]         256\n",
       "│    │    └─ReLU: 3-25                   [16, 128, 16, 16]         --\n",
       "├─Sequential: 1-7                        [16, 256, 8, 8]           --\n",
       "│    └─BasicBlock: 2-5                   [16, 256, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-26                 [16, 256, 8, 8]           294,912\n",
       "│    │    └─BatchNorm2d: 3-27            [16, 256, 8, 8]           512\n",
       "│    │    └─ReLU: 3-28                   [16, 256, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-29                 [16, 256, 8, 8]           589,824\n",
       "│    │    └─BatchNorm2d: 3-30            [16, 256, 8, 8]           512\n",
       "│    │    └─Sequential: 3-31             [16, 256, 8, 8]           33,280\n",
       "│    │    └─ReLU: 3-32                   [16, 256, 8, 8]           --\n",
       "│    └─BasicBlock: 2-6                   [16, 256, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-33                 [16, 256, 8, 8]           589,824\n",
       "│    │    └─BatchNorm2d: 3-34            [16, 256, 8, 8]           512\n",
       "│    │    └─ReLU: 3-35                   [16, 256, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-36                 [16, 256, 8, 8]           589,824\n",
       "│    │    └─BatchNorm2d: 3-37            [16, 256, 8, 8]           512\n",
       "│    │    └─ReLU: 3-38                   [16, 256, 8, 8]           --\n",
       "├─Sequential: 1-8                        [16, 512, 4, 4]           --\n",
       "│    └─BasicBlock: 2-7                   [16, 512, 4, 4]           --\n",
       "│    │    └─Conv2d: 3-39                 [16, 512, 4, 4]           1,179,648\n",
       "│    │    └─BatchNorm2d: 3-40            [16, 512, 4, 4]           1,024\n",
       "│    │    └─ReLU: 3-41                   [16, 512, 4, 4]           --\n",
       "│    │    └─Conv2d: 3-42                 [16, 512, 4, 4]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-43            [16, 512, 4, 4]           1,024\n",
       "│    │    └─Sequential: 3-44             [16, 512, 4, 4]           132,096\n",
       "│    │    └─ReLU: 3-45                   [16, 512, 4, 4]           --\n",
       "│    └─BasicBlock: 2-8                   [16, 512, 4, 4]           --\n",
       "│    │    └─Conv2d: 3-46                 [16, 512, 4, 4]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-47            [16, 512, 4, 4]           1,024\n",
       "│    │    └─ReLU: 3-48                   [16, 512, 4, 4]           --\n",
       "│    │    └─Conv2d: 3-49                 [16, 512, 4, 4]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-50            [16, 512, 4, 4]           1,024\n",
       "│    │    └─ReLU: 3-51                   [16, 512, 4, 4]           --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [16, 512, 1, 1]           --\n",
       "├─Linear: 1-10                           [16, 1000]                513,000\n",
       "==========================================================================================\n",
       "Total params: 11,689,512\n",
       "Trainable params: 11,689,512\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 9.48\n",
       "==========================================================================================\n",
       "Input size (MB): 3.15\n",
       "Forward/backward pass size (MB): 207.75\n",
       "Params size (MB): 46.76\n",
       "Estimated Total Size (MB): 257.65\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "summary(resnet, input_size=(batch_size, 3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, emb_space):\n",
    "        super(Encoder, self).__init__()\n",
    "        resnet = resnet18(pretrained=False)\n",
    "\n",
    "        if emb_space == 'tensor':\n",
    "            self.features = nn.Sequential(*list(resnet.children())[:-2])\n",
    "        elif emb_space == 'modulation':\n",
    "            self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
